{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/argonne-lcf/ai-science-training-series/blob/main/05_llm_part2/Intro_to_Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riLhjz2ZzQVX"
   },
   "source": [
    "# HW5\n",
    "Madusanka Madiligama \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DIqIqNCSzmUH",
    "outputId": "62dd5c81-c756-4ce9-fdc7-4dfc6115ce6a"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter huggingfacehub api token:  ········\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = getpass('Enter huggingfacehub api token: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "r1zjH-hC1XJ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/soft/applications/conda/2024-08-08/mconda3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "2024-11-18 18:54:05.923950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731956046.131732 3711848 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731956046.209242 3711848 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 18:54:06.786473: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539e5a5e781c4e54b6b369881dad6761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "# load model\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "# model = \"tiiuae/falcon-40b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "falcon_pipeline = transformers.pipeline(\"text-generation\",\n",
    "                                        model=model,\n",
    "                                        tokenizer=tokenizer,\n",
    "                                        torch_dtype=torch.bfloat16,\n",
    "                                        trust_remote_code=True,\n",
    "                                        device_map=\"auto\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pGVwRvNd1lbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.37527.sophia-pbs-01.lab.alcf.anl.gov/ipykernel_3711848/454465620.py:5: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  falcon = HuggingFaceHub(\n"
     ]
    }
   ],
   "source": [
    "# load remote model\n",
    "from langchain.llms import HuggingFaceHub\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "# model = \"tiiuae/falcon-40b-instruct\"\n",
    "falcon = HuggingFaceHub(\n",
    "    repo_id=model,\n",
    "    model_kwargs={\"temperature\": 0.5,\n",
    "                  \"max_length\": 128},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZsoDNet42sRA"
   },
   "outputs": [],
   "source": [
    "def get_completion_falcon(input, host=\"remote\", **kwargs):\n",
    "    prompt = f\"#### User: \\n{input}\\n\\n#### Response from falcon-7b-instruct:\"\n",
    "    response = \"\"\n",
    "    # print(prompt)\n",
    "    if host.lower() == \"local\":\n",
    "      print(\"invoking llm at Google Colab\")\n",
    "      if 'max_length' not in kwargs:\n",
    "        kwargs['max_length'] = 1000\n",
    "\n",
    "      falcon_response = falcon_pipeline(prompt,\n",
    "                                      #max_length=500,\n",
    "                                      do_sample=True,\n",
    "                                      top_k=10,\n",
    "                                      num_return_sequences=1,\n",
    "                                      eos_token_id=tokenizer.eos_token_id,\n",
    "                                      **kwargs,\n",
    "                                      )\n",
    "      response = falcon_response[0]['generated_text']\n",
    "\n",
    "    elif host.lower() == \"remote\":\n",
    "      print(\"invoking llm at Huggingface Hub\")\n",
    "      if \"max_length\" in kwargs:\n",
    "        kwargs['max_new_tokens'] = kwargs['max_length']\n",
    "\n",
    "      response = falcon.invoke(prompt, **kwargs)\n",
    "\n",
    "    else:\n",
    "      print (\"invalid host value, must be 'remote' or 'local'\")\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkexlqyIlk0y"
   },
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MekoIU8SlqIY"
   },
   "source": [
    "1. Load in a generative model using the HuggingFace pipeline. Use the zero-shot, few-shot, chain-of-thought, and few-shot chain-of-thought prompting to get the sum of odd numbers from a list of integers. In a few sentences describe what you learnt from each approach of prompting.\n",
    "- Next, play around with the temperature parameter. In a few sentences describe what you changes you notice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "T-zkEEeKlmRR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "\n",
      "\n",
      "You are a mathematical genius.\n",
      "\n",
      "Answer the following question directly.\n",
      "\n",
      "Q: Do the odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1?\n",
      "\n",
      "A:\n",
      "\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "\n",
      "Yes, the odd numbers in this group add up to an even number. The odd numbers are 1, 5, 13, and 82. The even numbers are 32 and 7. Therefore, the sum of the odd numbers is 13 and the sum of the even numbers is 32.\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\"max_length\": 1000}\n",
    "zero_shot_prompt = \"\"\"\n",
    "\n",
    "You are a mathematical genius.\n",
    "\n",
    "Answer the following question directly.\n",
    "\n",
    "Q: Do the odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1?\n",
    "\n",
    "A:\n",
    "\n",
    "\"\"\"\n",
    "zero_shot_prompt_explanation = get_completion_falcon(zero_shot_prompt, **kwargs)\n",
    "print(zero_shot_prompt_explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "\n",
      "\n",
      "You are a mathematical genius.\n",
      "\n",
      "Answer the questions using the following examples without showing detailed reasoning.\n",
      "\n",
      "Examples:\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
      "\n",
      "A: False\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
      "\n",
      "A: True\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
      "\n",
      "A: True\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
      "\n",
      "A: False\n",
      "\n",
      "Problem:\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
      "\n",
      "A:\n",
      "\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "\n",
      "Yes, the odd numbers in this group add up to an even number. The odd numbers 15 and 32, add up to an even number 32. The odd numbers 5 and 13, add up to an even number 13. The odd numbers 82 and 7, add up to an even number 82. The odd numbers 13 and 82, add up to an even number 82. The odd numbers 7 and 1, add up to an even number 7.\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\"max_length\": 1000}\n",
    "few_shot_prompt = \"\"\"\n",
    "\n",
    "You are a mathematical genius.\n",
    "\n",
    "Answer the questions using the following examples without showing detailed reasoning.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "\n",
    "A: False\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
    "\n",
    "A: True\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
    "\n",
    "A: True\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
    "\n",
    "A: False\n",
    "\n",
    "Problem:\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
    "\n",
    "A:\n",
    "\n",
    "\"\"\"\n",
    "few_shot_prompt_explanation = get_completion_falcon(few_shot_prompt, **kwargs)\n",
    "print(few_shot_prompt_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "\n",
      "\n",
      "You are a mathematical genius.\n",
      "\n",
      "Provide a detailed explanation for the answer to the question.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
      "\n",
      "A: The given numbers are: (15, 32, 5, 13, 82, 7, 1). First, identify the odd numbers within the list: (15, 5, 13, 7, 1). Next, add these odd numbers together: 15 + 5 + 13 + 7 + 1 equals 41. Since 41 is an odd number, the odd numbers do not add up to an even number, hence the answer is False.\n",
      "\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "\n",
      "The odd numbers in the given group add up to an even number: 15, 32, 5, 13, 82, 7, 1. This is a very simple problem, but it is a bit tricky. The odd numbers add up to an even number, so the answer is False.\n"
     ]
    }
   ],
   "source": [
    "COT_prompt = \"\"\"\n",
    "\n",
    "You are a mathematical genius.\n",
    "\n",
    "Provide a detailed explanation for the answer to the question.\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
    "\n",
    "A: The given numbers are: (15, 32, 5, 13, 82, 7, 1). First, identify the odd numbers within the list: (15, 5, 13, 7, 1). Next, add these odd numbers together: 15 + 5 + 13 + 7 + 1 equals 41. Since 41 is an odd number, the odd numbers do not add up to an even number, hence the answer is False.\n",
    "\n",
    "\"\"\"\n",
    "COT_prompt_explanation = get_completion_falcon(COT_prompt, **kwargs)\n",
    "\n",
    "print(COT_prompt_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "You are a mathematical genius.\n",
      "The template of the question is given as Q: [question]. The template of the answer is given as A: [answer].\n",
      "Help me solve the problem below using the examples given.\n",
      "\n",
      "Examples:\n",
      "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
      "A: The given numbers are: (4, 8, 9, 15, 12, 2, 1). Next select the odd numbers (9, 15, 1).  Adding all the selected odd numbers (9, 15, 1) gives 25. 25 is an odd number, hence the answer is False.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
      "A: The given numbers are: (17, 10, 19, 4, 8, 12, 24). Next select the odd numbers (17, 19).  Adding all the selected odd numbers (17, 19) gives 36. 36 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
      "A: The given numbers are: (16, 11, 14, 4, 8, 13, 24). Next select the odd numbers (11, 13).  Adding all the selected odd numbers (11, 13) gives 24. 24 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
      "A: The given numbers are: (17, 9, 10, 12, 13, 4, 2). Next select the odd numbers (17, 9, 13).  Adding all the selected odd numbers (17, 9, 13) gives 39. 39 is an odd number, hence the answer is False.\n",
      "\n",
      "Problem:\n",
      "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
      "A:\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "\n",
      "The answer to this problem is False.\n",
      "\n",
      "The given numbers are:\n",
      "\n",
      "15, 32, 5, 13, 82, 7, 1.\n",
      "\n",
      "The odd numbers in this group add up to an even number (15 + 32 = 47, 13 + 5 = 18, 82 + 7 = 89, 7 + 1 = 8).\n",
      "\n",
      "Therefore, the answer is False.\n"
     ]
    }
   ],
   "source": [
    "few_shot_COT_prompt =  \"\"\"You are a mathematical genius.\n",
    "The template of the question is given as Q: [question]. The template of the answer is given as A: [answer].\n",
    "Help me solve the problem below using the examples given.\n",
    "\n",
    "Examples:\n",
    "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: The given numbers are: (4, 8, 9, 15, 12, 2, 1). Next select the odd numbers (9, 15, 1).  Adding all the selected odd numbers (9, 15, 1) gives 25. 25 is an odd number, hence the answer is False.\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
    "A: The given numbers are: (17, 10, 19, 4, 8, 12, 24). Next select the odd numbers (17, 19).  Adding all the selected odd numbers (17, 19) gives 36. 36 is an even number, hence the answer is True.\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
    "A: The given numbers are: (16, 11, 14, 4, 8, 13, 24). Next select the odd numbers (11, 13).  Adding all the selected odd numbers (11, 13) gives 24. 24 is an even number, hence the answer is True.\n",
    "\n",
    "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
    "A: The given numbers are: (17, 9, 10, 12, 13, 4, 2). Next select the odd numbers (17, 9, 13).  Adding all the selected odd numbers (17, 9, 13) gives 39. 39 is an odd number, hence the answer is False.\n",
    "\n",
    "Problem:\n",
    "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
    "A:\n",
    "\"\"\"\n",
    "#15 + 5 + 13 + 7 + 1 = 41\n",
    "few_shot_COT_prompt_explanation = get_completion_falcon(few_shot_COT_prompt, **kwargs)\n",
    "print(few_shot_COT_prompt_explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "You are a mathematical genius.\n",
      "The template of the question is given as Q: [question]. The template of the answer is given as A: [answer].\n",
      "Help me solve the problem below using the examples given.\n",
      "\n",
      "Examples:\n",
      "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
      "A: The given numbers are: (4, 8, 9, 15, 12, 2, 1). Next select the odd numbers (9, 15, 1).  Adding all the selected odd numbers (9, 15, 1) gives 25. 25 is an odd number, hence the answer is False.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
      "A: The given numbers are: (17, 10, 19, 4, 8, 12, 24). Next select the odd numbers (17, 19).  Adding all the selected odd numbers (17, 19) gives 36. 36 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
      "A: The given numbers are: (16, 11, 14, 4, 8, 13, 24). Next select the odd numbers (11, 13).  Adding all the selected odd numbers (11, 13) gives 24. 24 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
      "A: The given numbers are: (17, 9, 10, 12, 13, 4, 2). Next select the odd numbers (17, 9, 13).  Adding all the selected odd numbers (17, 9, 13) gives 39. 39 is an odd number, hence the answer is False.\n",
      "\n",
      "Problem:\n",
      "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
      "A:\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "\n",
      "The answer is False.\n",
      "\n",
      "The given numbers are: (15, 32, 5, 13, 82, 7, 1). Next select the odd numbers (15, 32, 5, 13, 82, 7, 1).  Adding all the selected odd numbers (15, 32, 5, 13, 82, 7, 1) gives 32. 32 is an\n"
     ]
    }
   ],
   "source": [
    "temperature_value = 0.1  # Adjust the temperature value as needed between 0 and 1\n",
    "few_shot_COT_prompt_explanation = get_completion_falcon(few_shot_COT_prompt, temperature=temperature_value)\n",
    "\n",
    "print(few_shot_COT_prompt_explanation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "You are a mathematical genius.\n",
      "The template of the question is given as Q: [question]. The template of the answer is given as A: [answer].\n",
      "Help me solve the problem below using the examples given.\n",
      "\n",
      "Examples:\n",
      "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
      "A: The given numbers are: (4, 8, 9, 15, 12, 2, 1). Next select the odd numbers (9, 15, 1).  Adding all the selected odd numbers (9, 15, 1) gives 25. 25 is an odd number, hence the answer is False.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
      "A: The given numbers are: (17, 10, 19, 4, 8, 12, 24). Next select the odd numbers (17, 19).  Adding all the selected odd numbers (17, 19) gives 36. 36 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
      "A: The given numbers are: (16, 11, 14, 4, 8, 13, 24). Next select the odd numbers (11, 13).  Adding all the selected odd numbers (11, 13) gives 24. 24 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
      "A: The given numbers are: (17, 9, 10, 12, 13, 4, 2). Next select the odd numbers (17, 9, 13).  Adding all the selected odd numbers (17, 9, 13) gives 39. 39 is an odd number, hence the answer is False.\n",
      "\n",
      "Problem:\n",
      "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
      "A:\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "\n",
      "The answer to this problem is False. Here is the process I used to solve the problem:\n",
      "\n",
      "1. The given numbers are: (15, 32, 5, 13, 82, 7, 1).\n",
      "2. Next select the odd numbers (32, 5, 13, 82, 7, 1).\n",
      "3. Adding all the selected odd numbers (32, 5, 13, 82\n"
     ]
    }
   ],
   "source": [
    "temperature_value = 0.5  # Adjust the temperature value as needed between 0 and 1\n",
    "few_shot_COT_prompt_explanation_t5 = get_completion_falcon(few_shot_COT_prompt, temperature=temperature_value)\n",
    "\n",
    "print(few_shot_COT_prompt_explanation_t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invoking llm at Huggingface Hub\n",
      "#### User: \n",
      "You are a mathematical genius.\n",
      "The template of the question is given as Q: [question]. The template of the answer is given as A: [answer].\n",
      "Help me solve the problem below using the examples given.\n",
      "\n",
      "Examples:\n",
      "Q: The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
      "A: The given numbers are: (4, 8, 9, 15, 12, 2, 1). Next select the odd numbers (9, 15, 1).  Adding all the selected odd numbers (9, 15, 1) gives 25. 25 is an odd number, hence the answer is False.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 10, 19, 4, 8, 12, 24.\n",
      "A: The given numbers are: (17, 10, 19, 4, 8, 12, 24). Next select the odd numbers (17, 19).  Adding all the selected odd numbers (17, 19) gives 36. 36 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 16, 11, 14, 4, 8, 13, 24.\n",
      "A: The given numbers are: (16, 11, 14, 4, 8, 13, 24). Next select the odd numbers (11, 13).  Adding all the selected odd numbers (11, 13) gives 24. 24 is an even number, hence the answer is True.\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number: 17, 9, 10, 12, 13, 4, 2.\n",
      "A: The given numbers are: (17, 9, 10, 12, 13, 4, 2). Next select the odd numbers (17, 9, 13).  Adding all the selected odd numbers (17, 9, 13) gives 39. 39 is an odd number, hence the answer is False.\n",
      "\n",
      "Problem:\n",
      "Q: The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
      "A:\n",
      "\n",
      "\n",
      "#### Response from falcon-7b-instruct:\n",
      "False\n",
      "\n",
      "original question:\n",
      "\n",
      "Q: The odd numbers in this group add up to an even number:\n",
      "   9, 12, 15, 13, 14, 17, 25\\nA: 64\n",
      "A: False\n",
      "\n",
      "\n",
      "The logic seems to work, but the problem has an error in the formula. The answer is \"2 + 1 = 3 + 8 < 64\" instead of \"\n"
     ]
    }
   ],
   "source": [
    "temperature_value = 0.9  # Adjust the temperature value as needed between 0 and 1\n",
    "few_shot_COT_prompt_explanation_t9 = get_completion_falcon(few_shot_COT_prompt, temperature=temperature_value)\n",
    "\n",
    "print(few_shot_COT_prompt_explanation_t9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The varying temperature settings in the Falcon-7b-instruct model responses illustrate distinct impacts on output style and accuracy.​ At a low temperature of 0.1, the answers are conservative and deterministic, leading to straightforward conclusions like \"False,\" yet containing errors in identifying odd numbers due to a minimal creative approach. With a moderate temperature of 0.5, the output strikes a balance between coherence and creativity, repeating similar selection errors but demonstrating more detailed step-by-step engagement. At a high temperature of 0.9, the responses exhibit increased randomness and creative alterations, resulting in more diverse outputs but with a sacrifice in logical coherence and accuracy, highlighting the trade-off between creativity and factual correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOEwj0AKeV1VsbV3PwMuA5l",
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda/2024-08-08",
   "language": "python",
   "name": "2024-08-08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
